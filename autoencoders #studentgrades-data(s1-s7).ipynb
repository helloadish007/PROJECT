{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoEncoders\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MA101', 'PH100', ' BE10105', 'BE110', ' BE103', ' EC100', ' PH110',\n",
       "       ' EC110', ' CS110', 'CY100', 'BE100', 'EE100', 'CY110', 'EE110',\n",
       "       'MA102', 'BE102', 'CS100', 'CS120', 'CS202', 'IT202', 'IT204', 'HS200',\n",
       "       'MA202', 'CS208', 'IT232', 'IT234', 'CS305', 'IT301', 'IT303', 'IT305',\n",
       "       'IT307', 'IT341', 'IT331', 'IT333', 'IT367', 'IT363', 'HS300', 'CS304',\n",
       "       'IT304', 'IT306', 'IT364', 'IT302', 'IT332', 'IT334', 'IT352', 'IT366'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Importing the dataset\n",
    "data = pd.read_csv('all_sem_grades.csv')\n",
    "data= data.drop('NO.',axis=1)\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 46)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the training set and the test set\n",
    "training_set = pd.read_csv('all_train.csv')\n",
    "training_set= training_set.drop('NO.',axis=1)\n",
    "training_set = np.array(training_set, dtype = 'int')#user_id,movie_id,ratings\n",
    "test_set = pd.read_csv('all_test.csv')\n",
    "test_set= test_set.drop('NO.',axis=1)\n",
    "test_set = np.array(test_set, dtype = 'int')\n",
    "test_set.shape\n",
    "#training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 46)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape\n",
    "#training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nb_students = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "#nb_courses = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
    "nb_students = max(training_set.shape[0], test_set.shape[0])-1\n",
    "nb_courses = max(training_set.shape[1], test_set.shape[1])\n",
    "nb_students\n",
    "#nb_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting the data into Torch tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the architecture of the Neural Network\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_courses, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, nb_courses)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x.view(x.size(0), -1) \n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 2.0663810213106097e+18\n",
      "epoch: 2 loss: 2.0663810213106097e+18\n",
      "epoch: 3 loss: 2.0663810213106097e+18\n",
      "epoch: 4 loss: 2.0663810213106097e+18\n",
      "epoch: 5 loss: 2.0663810213106097e+18\n",
      "epoch: 6 loss: 2.0663810213106097e+18\n",
      "epoch: 7 loss: 2.0663810213106097e+18\n",
      "epoch: 8 loss: 2.0663810213106097e+18\n",
      "epoch: 9 loss: 2.0663810213106097e+18\n",
      "epoch: 10 loss: 2.0663810213106097e+18\n",
      "epoch: 11 loss: 2.0663810213106097e+18\n",
      "epoch: 12 loss: 2.0663810213106097e+18\n",
      "epoch: 13 loss: 2.0663810213106097e+18\n",
      "epoch: 14 loss: 2.0663810213106097e+18\n",
      "epoch: 15 loss: 2.0663810213106097e+18\n",
      "epoch: 16 loss: 2.0663810213106097e+18\n",
      "epoch: 17 loss: 2.0663810213106097e+18\n",
      "epoch: 18 loss: 2.0663810213106097e+18\n",
      "epoch: 19 loss: 2.0663810213106097e+18\n",
      "epoch: 20 loss: 2.0663810213106097e+18\n",
      "epoch: 21 loss: 2.0663810213106097e+18\n",
      "epoch: 22 loss: 2.0663810213106097e+18\n",
      "epoch: 23 loss: 2.0663810213106097e+18\n",
      "epoch: 24 loss: 2.0663810213106097e+18\n",
      "epoch: 25 loss: 2.0663810213106097e+18\n",
      "epoch: 26 loss: 2.0663810213106097e+18\n",
      "epoch: 27 loss: 2.0663810213106097e+18\n",
      "epoch: 28 loss: 2.0663810213106097e+18\n",
      "epoch: 29 loss: 2.0663810213106097e+18\n",
      "epoch: 30 loss: 2.0663810213106097e+18\n",
      "epoch: 31 loss: 2.0663810213106097e+18\n",
      "epoch: 32 loss: 2.0663810213106097e+18\n",
      "epoch: 33 loss: 2.0663810213106097e+18\n",
      "epoch: 34 loss: 2.0663810213106097e+18\n",
      "epoch: 35 loss: 2.0663810213106097e+18\n",
      "epoch: 36 loss: 2.0663810213106097e+18\n",
      "epoch: 37 loss: 2.0663810213106097e+18\n",
      "epoch: 38 loss: 2.0663810213106097e+18\n",
      "epoch: 39 loss: 2.0663810213106097e+18\n",
      "epoch: 40 loss: 2.0663810213106097e+18\n",
      "epoch: 41 loss: 2.0663810213106097e+18\n",
      "epoch: 42 loss: 2.0663810213106097e+18\n",
      "epoch: 43 loss: 2.0663810213106097e+18\n",
      "epoch: 44 loss: 2.0663810213106097e+18\n",
      "epoch: 45 loss: 2.0663810213106097e+18\n",
      "epoch: 46 loss: 2.0663810213106097e+18\n",
      "epoch: 47 loss: 2.0663810213106097e+18\n",
      "epoch: 48 loss: 2.0663810213106097e+18\n",
      "epoch: 49 loss: 2.0663810213106097e+18\n",
      "epoch: 50 loss: 2.0663810213106097e+18\n",
      "epoch: 51 loss: 2.0663810213106097e+18\n",
      "epoch: 52 loss: 2.0663810213106097e+18\n",
      "epoch: 53 loss: 2.0663810213106097e+18\n",
      "epoch: 54 loss: 2.0663810213106097e+18\n",
      "epoch: 55 loss: 2.0663810213106097e+18\n",
      "epoch: 56 loss: 2.0663810213106097e+18\n",
      "epoch: 57 loss: 2.0663810213106097e+18\n",
      "epoch: 58 loss: 2.0663810213106097e+18\n",
      "epoch: 59 loss: 2.0663810213106097e+18\n",
      "epoch: 60 loss: 2.0663810213106097e+18\n",
      "epoch: 61 loss: 2.0663810213106097e+18\n",
      "epoch: 62 loss: 2.0663810213106097e+18\n",
      "epoch: 63 loss: 2.0663810213106097e+18\n",
      "epoch: 64 loss: 2.0663810213106097e+18\n",
      "epoch: 65 loss: 2.0663810213106097e+18\n",
      "epoch: 66 loss: 2.0663810213106097e+18\n",
      "epoch: 67 loss: 2.0663810213106097e+18\n",
      "epoch: 68 loss: 2.0663810213106097e+18\n",
      "epoch: 69 loss: 2.0663810213106097e+18\n",
      "epoch: 70 loss: 2.0663810213106097e+18\n",
      "epoch: 71 loss: 2.0663810213106097e+18\n",
      "epoch: 72 loss: 2.0663810213106097e+18\n",
      "epoch: 73 loss: 2.0663810213106097e+18\n",
      "epoch: 74 loss: 2.0663810213106097e+18\n",
      "epoch: 75 loss: 2.0663810213106097e+18\n",
      "epoch: 76 loss: 2.0663810213106097e+18\n",
      "epoch: 77 loss: 2.0663810213106097e+18\n",
      "epoch: 78 loss: 2.0663810213106097e+18\n",
      "epoch: 79 loss: 2.0663810213106097e+18\n",
      "epoch: 80 loss: 2.0663810213106097e+18\n",
      "epoch: 81 loss: 2.0663810213106097e+18\n",
      "epoch: 82 loss: 2.0663810213106097e+18\n",
      "epoch: 83 loss: 2.0663810213106097e+18\n",
      "epoch: 84 loss: 2.0663810213106097e+18\n",
      "epoch: 85 loss: 2.0663810213106097e+18\n",
      "epoch: 86 loss: 2.0663810213106097e+18\n",
      "epoch: 87 loss: 2.0663810213106097e+18\n",
      "epoch: 88 loss: 2.0663810213106097e+18\n",
      "epoch: 89 loss: 2.0663810213106097e+18\n",
      "epoch: 90 loss: 2.0663810213106097e+18\n",
      "epoch: 91 loss: 2.0663810213106097e+18\n",
      "epoch: 92 loss: 2.0663810213106097e+18\n",
      "epoch: 93 loss: 2.0663810213106097e+18\n",
      "epoch: 94 loss: 2.0663810213106097e+18\n",
      "epoch: 95 loss: 2.0663810213106097e+18\n",
      "epoch: 96 loss: 2.0663810213106097e+18\n",
      "epoch: 97 loss: 2.0663810213106097e+18\n",
      "epoch: 98 loss: 2.0663810213106097e+18\n",
      "epoch: 99 loss: 2.0663810213106097e+18\n",
      "epoch: 100 loss: 2.0663810213106097e+18\n",
      "epoch: 101 loss: 2.0663810213106097e+18\n",
      "epoch: 102 loss: 2.0663810213106097e+18\n",
      "epoch: 103 loss: 2.0663810213106097e+18\n",
      "epoch: 104 loss: 2.0663810213106097e+18\n",
      "epoch: 105 loss: 2.0663810213106097e+18\n",
      "epoch: 106 loss: 2.0663810213106097e+18\n",
      "epoch: 107 loss: 2.0663810213106097e+18\n",
      "epoch: 108 loss: 2.0663810213106097e+18\n",
      "epoch: 109 loss: 2.0663810213106097e+18\n",
      "epoch: 110 loss: 2.0663810213106097e+18\n",
      "epoch: 111 loss: 2.0663810213106097e+18\n",
      "epoch: 112 loss: 2.0663810213106097e+18\n",
      "epoch: 113 loss: 2.0663810213106097e+18\n",
      "epoch: 114 loss: 2.0663810213106097e+18\n",
      "epoch: 115 loss: 2.0663810213106097e+18\n",
      "epoch: 116 loss: 2.0663810213106097e+18\n",
      "epoch: 117 loss: 2.0663810213106097e+18\n",
      "epoch: 118 loss: 2.0663810213106097e+18\n",
      "epoch: 119 loss: 2.0663810213106097e+18\n",
      "epoch: 120 loss: 2.0663810213106097e+18\n",
      "epoch: 121 loss: 2.0663810213106097e+18\n",
      "epoch: 122 loss: 2.0663810213106097e+18\n",
      "epoch: 123 loss: 2.0663810213106097e+18\n",
      "epoch: 124 loss: 2.0663810213106097e+18\n",
      "epoch: 125 loss: 2.0663810213106097e+18\n",
      "epoch: 126 loss: 2.0663810213106097e+18\n",
      "epoch: 127 loss: 2.0663810213106097e+18\n",
      "epoch: 128 loss: 2.0663810213106097e+18\n",
      "epoch: 129 loss: 2.0663810213106097e+18\n",
      "epoch: 130 loss: 2.0663810213106097e+18\n",
      "epoch: 131 loss: 2.0663810213106097e+18\n",
      "epoch: 132 loss: 2.0663810213106097e+18\n",
      "epoch: 133 loss: 2.0663810213106097e+18\n",
      "epoch: 134 loss: 2.0663810213106097e+18\n",
      "epoch: 135 loss: 2.0663810213106097e+18\n",
      "epoch: 136 loss: 2.0663810213106097e+18\n",
      "epoch: 137 loss: 2.0663810213106097e+18\n",
      "epoch: 138 loss: 2.0663810213106097e+18\n",
      "epoch: 139 loss: 2.0663810213106097e+18\n",
      "epoch: 140 loss: 2.0663810213106097e+18\n",
      "epoch: 141 loss: 2.0663810213106097e+18\n",
      "epoch: 142 loss: 2.0663810213106097e+18\n",
      "epoch: 143 loss: 2.0663810213106097e+18\n",
      "epoch: 144 loss: 2.0663810213106097e+18\n",
      "epoch: 145 loss: 2.0663810213106097e+18\n",
      "epoch: 146 loss: 2.0663810213106097e+18\n",
      "epoch: 147 loss: 2.0663810213106097e+18\n",
      "epoch: 148 loss: 2.0663810213106097e+18\n",
      "epoch: 149 loss: 2.0663810213106097e+18\n",
      "epoch: 150 loss: 2.0663810213106097e+18\n",
      "epoch: 151 loss: 2.0663810213106097e+18\n",
      "epoch: 152 loss: 2.0663810213106097e+18\n",
      "epoch: 153 loss: 2.0663810213106097e+18\n",
      "epoch: 154 loss: 2.0663810213106097e+18\n",
      "epoch: 155 loss: 2.0663810213106097e+18\n",
      "epoch: 156 loss: 2.0663810213106097e+18\n",
      "epoch: 157 loss: 2.0663810213106097e+18\n",
      "epoch: 158 loss: 2.0663810213106097e+18\n",
      "epoch: 159 loss: 2.0663810213106097e+18\n",
      "epoch: 160 loss: 2.0663810213106097e+18\n",
      "epoch: 161 loss: 2.0663810213106097e+18\n",
      "epoch: 162 loss: 2.0663810213106097e+18\n",
      "epoch: 163 loss: 2.0663810213106097e+18\n",
      "epoch: 164 loss: 2.0663810213106097e+18\n",
      "epoch: 165 loss: 2.0663810213106097e+18\n",
      "epoch: 166 loss: 2.0663810213106097e+18\n",
      "epoch: 167 loss: 2.0663810213106097e+18\n",
      "epoch: 168 loss: 2.0663810213106097e+18\n",
      "epoch: 169 loss: 2.0663810213106097e+18\n",
      "epoch: 170 loss: 2.0663810213106097e+18\n",
      "epoch: 171 loss: 2.0663810213106097e+18\n",
      "epoch: 172 loss: 2.0663810213106097e+18\n",
      "epoch: 173 loss: 2.0663810213106097e+18\n",
      "epoch: 174 loss: 2.0663810213106097e+18\n",
      "epoch: 175 loss: 2.0663810213106097e+18\n",
      "epoch: 176 loss: 2.0663810213106097e+18\n",
      "epoch: 177 loss: 2.0663810213106097e+18\n",
      "epoch: 178 loss: 2.0663810213106097e+18\n",
      "epoch: 179 loss: 2.0663810213106097e+18\n",
      "epoch: 180 loss: 2.0663810213106097e+18\n",
      "epoch: 181 loss: 2.0663810213106097e+18\n",
      "epoch: 182 loss: 2.0663810213106097e+18\n",
      "epoch: 183 loss: 2.0663810213106097e+18\n",
      "epoch: 184 loss: 2.0663810213106097e+18\n",
      "epoch: 185 loss: 2.0663810213106097e+18\n",
      "epoch: 186 loss: 2.0663810213106097e+18\n",
      "epoch: 187 loss: 2.0663810213106097e+18\n",
      "epoch: 188 loss: 2.0663810213106097e+18\n",
      "epoch: 189 loss: 2.0663810213106097e+18\n",
      "epoch: 190 loss: 2.0663810213106097e+18\n",
      "epoch: 191 loss: 2.0663810213106097e+18\n",
      "epoch: 192 loss: 2.0663810213106097e+18\n",
      "epoch: 193 loss: 2.0663810213106097e+18\n",
      "epoch: 194 loss: 2.0663810213106097e+18\n",
      "epoch: 195 loss: 2.0663810213106097e+18\n",
      "epoch: 196 loss: 2.0663810213106097e+18\n",
      "epoch: 197 loss: 2.0663810213106097e+18\n",
      "epoch: 198 loss: 2.0663810213106097e+18\n",
      "epoch: 199 loss: 2.0663810213106097e+18\n",
      "epoch: 200 loss: 2.0663810213106097e+18\n"
     ]
    }
   ],
   "source": [
    "# Training the SAE\n",
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_students):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_courses/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            \n",
    "            train_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.0880597246636442e+18\n"
     ]
    }
   ],
   "source": [
    "# Testing the SAE\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_students):\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "    #target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "for id_user in range(test_set.shape[0]):\n",
    "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "\n",
    "\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_courses/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MA101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PH100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BE10105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>BE110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BE103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>EC100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PH110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>EC110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CS110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>CY100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>BE100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>EE100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>CY110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>EE110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>MA102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>BE102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>CS100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>CS120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>CS202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>IT202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>IT204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>HS200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>MA202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>CS208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>IT232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>IT234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>CS305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>IT301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>IT303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>IT305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>IT307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>IT341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>IT331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>IT333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>IT367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>IT363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>HS300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>CS304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>IT304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>IT306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>IT364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>IT302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>IT332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>IT334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>IT352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>IT366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0      MA101\n",
       "1      PH100\n",
       "2    BE10105\n",
       "3      BE110\n",
       "4      BE103\n",
       "5      EC100\n",
       "6      PH110\n",
       "7      EC110\n",
       "8      CS110\n",
       "9      CY100\n",
       "10     BE100\n",
       "11     EE100\n",
       "12     CY110\n",
       "13     EE110\n",
       "14     MA102\n",
       "15     BE102\n",
       "16     CS100\n",
       "17     CS120\n",
       "18     CS202\n",
       "19     IT202\n",
       "20     IT204\n",
       "21     HS200\n",
       "22     MA202\n",
       "23     CS208\n",
       "24     IT232\n",
       "25     IT234\n",
       "26     CS305\n",
       "27     IT301\n",
       "28     IT303\n",
       "29     IT305\n",
       "30     IT307\n",
       "31     IT341\n",
       "32     IT331\n",
       "33     IT333\n",
       "34     IT367\n",
       "35     IT363\n",
       "36     HS300\n",
       "37     CS304\n",
       "38     IT304\n",
       "39     IT306\n",
       "40     IT364\n",
       "41     IT302\n",
       "42     IT332\n",
       "43     IT334\n",
       "44     IT352\n",
       "45     IT366"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=data.columns\n",
    "c=columns.tolist()\n",
    "d=pd.DataFrame(c)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = 2\n",
    "\n",
    "student_grade = training_set.data.numpy()[student_id, :].reshape(-1,1)\n",
    "user_target = test_set.data.numpy()[student_id, :].reshape(-1,1)\n",
    " \n",
    "user_input = Variable(training_set[student_id]).unsqueeze(0)\n",
    "predicted = sae(user_input)\n",
    "predicted = predicted.data.numpy().reshape(-1,1)\n",
    "# Join all info in one dataset\n",
    "result_array = np.hstack([d, user_target, predicted])\n",
    "result_array = result_array[result_array[:, 1] > 0]\n",
    "result_df = pd.DataFrame(data=result_array, columns=['courses', 'Target Rating', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courses</th>\n",
       "      <th>Target Rating</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MA101</td>\n",
       "      <td>7</td>\n",
       "      <td>5.50504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PH100</td>\n",
       "      <td>6</td>\n",
       "      <td>7.16058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BE10105</td>\n",
       "      <td>5</td>\n",
       "      <td>7.5648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>BE110</td>\n",
       "      <td>9</td>\n",
       "      <td>8.43282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BE103</td>\n",
       "      <td>7</td>\n",
       "      <td>6.11273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>EC100</td>\n",
       "      <td>6</td>\n",
       "      <td>6.5294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PH110</td>\n",
       "      <td>10</td>\n",
       "      <td>9.51373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>EC110</td>\n",
       "      <td>9</td>\n",
       "      <td>11.0226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CS110</td>\n",
       "      <td>9</td>\n",
       "      <td>10.1607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>CY100</td>\n",
       "      <td>6</td>\n",
       "      <td>6.09016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>BE100</td>\n",
       "      <td>7</td>\n",
       "      <td>6.54098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>EE100</td>\n",
       "      <td>8</td>\n",
       "      <td>6.02156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>CY110</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>EE110</td>\n",
       "      <td>10</td>\n",
       "      <td>11.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>MA102</td>\n",
       "      <td>7</td>\n",
       "      <td>8.55718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>BE102</td>\n",
       "      <td>9</td>\n",
       "      <td>6.78969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>CS100</td>\n",
       "      <td>5</td>\n",
       "      <td>8.23788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>CS120</td>\n",
       "      <td>10</td>\n",
       "      <td>9.29106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>CS202</td>\n",
       "      <td>5</td>\n",
       "      <td>6.03206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>IT202</td>\n",
       "      <td>5</td>\n",
       "      <td>5.91308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>IT204</td>\n",
       "      <td>8</td>\n",
       "      <td>7.45685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>HS200</td>\n",
       "      <td>7</td>\n",
       "      <td>7.67133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>MA202</td>\n",
       "      <td>9</td>\n",
       "      <td>8.93485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>CS208</td>\n",
       "      <td>7</td>\n",
       "      <td>5.80528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>IT232</td>\n",
       "      <td>10</td>\n",
       "      <td>9.93293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>IT234</td>\n",
       "      <td>10</td>\n",
       "      <td>8.97993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>CS305</td>\n",
       "      <td>7</td>\n",
       "      <td>7.70031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>IT301</td>\n",
       "      <td>7</td>\n",
       "      <td>7.58146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>IT303</td>\n",
       "      <td>7</td>\n",
       "      <td>4.61904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>IT305</td>\n",
       "      <td>7</td>\n",
       "      <td>6.01334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>IT307</td>\n",
       "      <td>7</td>\n",
       "      <td>6.42678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>IT341</td>\n",
       "      <td>10</td>\n",
       "      <td>9.99417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>IT331</td>\n",
       "      <td>10</td>\n",
       "      <td>8.55774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>IT333</td>\n",
       "      <td>9</td>\n",
       "      <td>10.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>IT363</td>\n",
       "      <td>6</td>\n",
       "      <td>-74.5178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>HS300</td>\n",
       "      <td>7</td>\n",
       "      <td>6.89198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>CS304</td>\n",
       "      <td>7</td>\n",
       "      <td>6.06645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>IT304</td>\n",
       "      <td>9</td>\n",
       "      <td>9.12757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>IT306</td>\n",
       "      <td>8</td>\n",
       "      <td>9.86032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>IT364</td>\n",
       "      <td>8</td>\n",
       "      <td>-88.4348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     courses Target Rating Predicted\n",
       "0      MA101             7   5.50504\n",
       "1      PH100             6   7.16058\n",
       "2    BE10105             5    7.5648\n",
       "3      BE110             9   8.43282\n",
       "4      BE103             7   6.11273\n",
       "5      EC100             6    6.5294\n",
       "6      PH110            10   9.51373\n",
       "7      EC110             9   11.0226\n",
       "8      CS110             9   10.1607\n",
       "9      CY100             6   6.09016\n",
       "10     BE100             7   6.54098\n",
       "11     EE100             8   6.02156\n",
       "12     CY110            10        10\n",
       "13     EE110            10   11.1428\n",
       "14     MA102             7   8.55718\n",
       "15     BE102             9   6.78969\n",
       "16     CS100             5   8.23788\n",
       "17     CS120            10   9.29106\n",
       "18     CS202             5   6.03206\n",
       "19     IT202             5   5.91308\n",
       "20     IT204             8   7.45685\n",
       "21     HS200             7   7.67133\n",
       "22     MA202             9   8.93485\n",
       "23     CS208             7   5.80528\n",
       "24     IT232            10   9.93293\n",
       "25     IT234            10   8.97993\n",
       "26     CS305             7   7.70031\n",
       "27     IT301             7   7.58146\n",
       "28     IT303             7   4.61904\n",
       "29     IT305             7   6.01334\n",
       "30     IT307             7   6.42678\n",
       "31     IT341            10   9.99417\n",
       "32     IT331            10   8.55774\n",
       "33     IT333             9    10.963\n",
       "34     IT363             6  -74.5178\n",
       "35     HS300             7   6.89198\n",
       "36     CS304             7   6.06645\n",
       "37     IT304             9   9.12757\n",
       "38     IT306             8   9.86032\n",
       "39     IT364             8  -88.4348"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

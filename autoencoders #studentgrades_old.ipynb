{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoEncoders\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing the dataset\n",
    "data = pd.read_csv('s1_improvised_only_grades.csv')\n",
    "data= data.drop('NO.',axis=1)\n",
    "\n",
    "# users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "# ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 9)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the training set and the test set\n",
    "training_set = pd.read_csv('s1_train.csv')\n",
    "training_set= training_set.drop('NO.',axis=1)\n",
    "training_set = np.array(training_set, dtype = 'int')#user_id,movie_id,ratings\n",
    "test_set = pd.read_csv('s1_test.csv')\n",
    "test_set= test_set.drop('NO.',axis=1)\n",
    "test_set = np.array(test_set, dtype = 'int')\n",
    "test_set.shape\n",
    "#training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 9)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape\n",
    "#training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nb_students = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "#nb_courses = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
    "nb_students = max(training_set.shape[0], test_set.shape[0])-1\n",
    "nb_courses = max(training_set.shape[1], test_set.shape[1])\n",
    "nb_students\n",
    "#nb_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Converting the data into an array with users in lines and movies in columns\n",
    "# def convert(data):\n",
    "#     new_data = []\n",
    "#     for id_users in range(1, nb_users + 1):\n",
    "#         id_movies = data[:,1][data[:,0] == id_users]\n",
    "#         id_ratings = data[:,2][data[:,0] == id_users]\n",
    "#         ratings = np.zeros(nb_movies)\n",
    "#         ratings[id_movies - 1] = id_ratings\n",
    "#         new_data.append(list(ratings))\n",
    "#     return new_data\n",
    "# training_set = convert(training_set)\n",
    "# test_set = convert(test_set)\n",
    "# training_set= training_set.drop('NO',axis=1)\n",
    "# test_set= training_set.drop('NO',axis=1)\n",
    "\n",
    "# Converting the data into Torch tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the architecture of the Neural Network\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_courses, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, nb_courses)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x.view(x.size(0), -1) \n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training the SAE\n",
    "# nb_epoch = 200\n",
    "# for epoch in range(1, nb_epoch + 1):\n",
    "#     train_loss = 0\n",
    "#     s = 0.\n",
    "#     for id_user in range(nb_users):\n",
    "#         input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "#         target = input.clone()\n",
    "#         if torch.sum(target.data > 0) > 0:\n",
    "#             output = sae(input)\n",
    "#             target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "#             output[target == 0] = 0\n",
    "#             loss = criterion(output, target)\n",
    "#             mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "#             loss.backward()\n",
    "#             train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "#             s += 1.\n",
    "#             optimizer.step()\n",
    "#     print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing the SAE\n",
    "# test_loss = 0\n",
    "# s = 0.\n",
    "# for id_user in range(nb_users):\n",
    "#     input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "#     #target = Variable(test_set[id_user])\n",
    "#     target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "#     if torch.sum(target.data > 0) > 0:\n",
    "#         output = sae(input)\n",
    "#         target.require_grad = False\n",
    "#         output[(target == 0).unsqueeze(0)] = 0\n",
    "#         loss = criterion(output, target)\n",
    "#         mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "#         test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "#         s += 1.\n",
    "# print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training the SAE\n",
    "# nb_epoch = 200\n",
    "# for epoch in range(1, nb_epoch + 1):\n",
    "#     train_loss = 0\n",
    "#     s = 0.\n",
    "#     for id_user in range(nb_students):\n",
    "#         input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "#         target = input.clone()\n",
    "    \n",
    "#         if torch.sum(target.data > 0) > 0:\n",
    "#             output = sae(input.unsqueeze_(2))\n",
    "#             print(input.shape)\n",
    "#             target.require_grad = False\n",
    "#             output[target == 0] = 0\n",
    "#             loss = criterion(output, target)\n",
    "#             mean_corrector = nb_courses/float(torch.sum(target.data > 0) + 1e-10)\n",
    "#             loss.backward()\n",
    "#             #train_loss += np.sqrt(loss.data[0]*mean_corrector)\n",
    "#             train_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "\n",
    "#             s += 1.\n",
    "#             optimizer.step()\n",
    "#     print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "# # data = data.view(data.size(0), -1)\n",
    "# # output = model(data)[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 2.667836700131636\n",
      "epoch: 2 loss: 2.0094775790842117\n",
      "epoch: 3 loss: 1.973593640106903\n",
      "epoch: 4 loss: 1.9545548520625307\n",
      "epoch: 5 loss: 2.0921537637861567\n",
      "epoch: 6 loss: 2.2826654946161575\n",
      "epoch: 7 loss: 2.12166120505108\n",
      "epoch: 8 loss: 1.7192527496096939\n",
      "epoch: 9 loss: 1.93712849460893\n",
      "epoch: 10 loss: 1.88637620735018\n",
      "epoch: 11 loss: 1.9746038734889761\n",
      "epoch: 12 loss: 1.7509764883229686\n",
      "epoch: 13 loss: 1.605379937247395\n",
      "epoch: 14 loss: 1.6935663302931097\n",
      "epoch: 15 loss: 1.7068470101630264\n",
      "epoch: 16 loss: 1.9402216364876819\n",
      "epoch: 17 loss: 1.8702705514303892\n",
      "epoch: 18 loss: 1.6368472966619105\n",
      "epoch: 19 loss: 1.7890178563606949\n",
      "epoch: 20 loss: 1.6608327905236198\n",
      "epoch: 21 loss: 1.671960764138635\n",
      "epoch: 22 loss: 1.9513138647507755\n",
      "epoch: 23 loss: 1.883091554445884\n",
      "epoch: 24 loss: 1.6976882193813727\n",
      "epoch: 25 loss: 1.9066723084332884\n",
      "epoch: 26 loss: 1.7744466530485057\n",
      "epoch: 27 loss: 1.631819798843946\n",
      "epoch: 28 loss: 1.7298206660713884\n",
      "epoch: 29 loss: 1.7904319879858548\n",
      "epoch: 30 loss: 1.7371712157067845\n",
      "epoch: 31 loss: 1.7103295428800716\n",
      "epoch: 32 loss: 1.8488775204133319\n",
      "epoch: 33 loss: 1.7350247739174953\n",
      "epoch: 34 loss: 1.5051844182358003\n",
      "epoch: 35 loss: 1.708178756796756\n",
      "epoch: 36 loss: 1.845700903712061\n",
      "epoch: 37 loss: 1.8427557407375257\n",
      "epoch: 38 loss: 1.7393236048865186\n",
      "epoch: 39 loss: 1.75515552693098\n",
      "epoch: 40 loss: 1.5737662867367308\n",
      "epoch: 41 loss: 1.5546800066766697\n",
      "epoch: 42 loss: 1.9009264899513312\n",
      "epoch: 43 loss: 1.9523623881134677\n",
      "epoch: 44 loss: 1.720282714014361\n",
      "epoch: 45 loss: 1.5747241720394054\n",
      "epoch: 46 loss: 1.5557824443688975\n",
      "epoch: 47 loss: 1.4913418191894015\n",
      "epoch: 48 loss: 1.7428654742463328\n",
      "epoch: 49 loss: 1.9427945631214003\n",
      "epoch: 50 loss: 1.76809316508183\n",
      "epoch: 51 loss: 1.511695308766088\n",
      "epoch: 52 loss: 1.5548514163689926\n",
      "epoch: 53 loss: 1.5800845371491559\n",
      "epoch: 54 loss: 1.6459525154553265\n",
      "epoch: 55 loss: 1.7687323200461567\n",
      "epoch: 56 loss: 1.618420173550558\n",
      "epoch: 57 loss: 1.4305064490895458\n",
      "epoch: 58 loss: 1.541485008546169\n",
      "epoch: 59 loss: 1.7292544916283266\n",
      "epoch: 60 loss: 1.7044134960611235\n",
      "epoch: 61 loss: 1.597913626995597\n",
      "epoch: 62 loss: 1.7387118973611517\n",
      "epoch: 63 loss: 1.6684517245896775\n",
      "epoch: 64 loss: 1.618218692719395\n",
      "epoch: 65 loss: 1.7717200774239366\n",
      "epoch: 66 loss: 1.6779044945737578\n",
      "epoch: 67 loss: 1.4851305513749824\n",
      "epoch: 68 loss: 1.61544600849283\n",
      "epoch: 69 loss: 1.7514659169291389\n",
      "epoch: 70 loss: 1.5698102236701412\n",
      "epoch: 71 loss: 1.5458296481354097\n",
      "epoch: 72 loss: 1.6753364785385885\n",
      "epoch: 73 loss: 1.626506781056739\n",
      "epoch: 74 loss: 1.5853435643576406\n",
      "epoch: 75 loss: 1.7774246793341584\n",
      "epoch: 76 loss: 1.6611493902769379\n",
      "epoch: 77 loss: 1.4244362135256483\n",
      "epoch: 78 loss: 1.6423197039528645\n",
      "epoch: 79 loss: 1.7537840764186152\n",
      "epoch: 80 loss: 1.705389765837818\n",
      "epoch: 81 loss: 1.6511400083397452\n",
      "epoch: 82 loss: 1.5305075192124376\n",
      "epoch: 83 loss: 1.4684593199572553\n",
      "epoch: 84 loss: 1.5949168194245176\n",
      "epoch: 85 loss: 1.7723695296928281\n",
      "epoch: 86 loss: 1.5585340348619316\n",
      "epoch: 87 loss: 1.4210733686315506\n",
      "epoch: 88 loss: 1.5852096997937501\n",
      "epoch: 89 loss: 1.5414248316348704\n",
      "epoch: 90 loss: 1.5936442819092538\n",
      "epoch: 91 loss: 1.7081757215784046\n",
      "epoch: 92 loss: 1.6265781084245592\n",
      "epoch: 93 loss: 1.5854926181841615\n",
      "epoch: 94 loss: 1.6081249484044076\n",
      "epoch: 95 loss: 1.648055147026761\n",
      "epoch: 96 loss: 1.576461986658575\n",
      "epoch: 97 loss: 1.5829815572066592\n",
      "epoch: 98 loss: 1.6285601551299773\n",
      "epoch: 99 loss: 1.5461929912054257\n",
      "epoch: 100 loss: 1.5787397355495567\n",
      "epoch: 101 loss: 1.6507401355318942\n",
      "epoch: 102 loss: 1.5634617736796503\n",
      "epoch: 103 loss: 1.5832223954828815\n",
      "epoch: 104 loss: 1.677327354580925\n",
      "epoch: 105 loss: 1.5584409244618738\n",
      "epoch: 106 loss: 1.5302256264672538\n",
      "epoch: 107 loss: 1.6318757733212519\n",
      "epoch: 108 loss: 1.6485946973754135\n",
      "epoch: 109 loss: 1.5857815680498153\n",
      "epoch: 110 loss: 1.5849760137953934\n",
      "epoch: 111 loss: 1.6076931107779582\n",
      "epoch: 112 loss: 1.5111351148028793\n",
      "epoch: 113 loss: 1.568718812739059\n",
      "epoch: 114 loss: 1.7484280919118773\n",
      "epoch: 115 loss: 1.6334585704192655\n",
      "epoch: 116 loss: 1.4410024979356648\n",
      "epoch: 117 loss: 1.6155012693294561\n",
      "epoch: 118 loss: 1.6343348507309312\n",
      "epoch: 119 loss: 1.5481815301732085\n",
      "epoch: 120 loss: 1.692843183122808\n",
      "epoch: 121 loss: 1.6009914790532787\n",
      "epoch: 122 loss: 1.4092849504088938\n",
      "epoch: 123 loss: 1.6361281473725442\n",
      "epoch: 124 loss: 1.716969524433654\n",
      "epoch: 125 loss: 1.5891410532613215\n",
      "epoch: 126 loss: 1.566258942815599\n",
      "epoch: 127 loss: 1.57138766097894\n",
      "epoch: 128 loss: 1.5379855609519129\n",
      "epoch: 129 loss: 1.6360319433116248\n",
      "epoch: 130 loss: 1.7472321797153463\n",
      "epoch: 131 loss: 1.5340565134737911\n",
      "epoch: 132 loss: 1.4464490772973126\n",
      "epoch: 133 loss: 1.6357616491272426\n",
      "epoch: 134 loss: 1.6141123272721218\n",
      "epoch: 135 loss: 1.6129201740349794\n",
      "epoch: 136 loss: 1.7170953613185793\n",
      "epoch: 137 loss: 1.490154313480415\n",
      "epoch: 138 loss: 1.4691966325143415\n",
      "epoch: 139 loss: 1.6516651056562102\n",
      "epoch: 140 loss: 1.668901246721332\n",
      "epoch: 141 loss: 1.5661691868758485\n",
      "epoch: 142 loss: 1.546785237454822\n",
      "epoch: 143 loss: 1.6299730473186242\n",
      "epoch: 144 loss: 1.59363852488546\n",
      "epoch: 145 loss: 1.6072918604852242\n",
      "epoch: 146 loss: 1.6761370698635372\n",
      "epoch: 147 loss: 1.5361658747876572\n",
      "epoch: 148 loss: 1.4988578687448502\n",
      "epoch: 149 loss: 1.6969053477042269\n",
      "epoch: 150 loss: 1.692545204933298\n",
      "epoch: 151 loss: 1.5392855507836818\n",
      "epoch: 152 loss: 1.5193901800800131\n",
      "epoch: 153 loss: 1.5440994047730843\n",
      "epoch: 154 loss: 1.5714206073181418\n",
      "epoch: 155 loss: 1.6819524090429026\n",
      "epoch: 156 loss: 1.7191948623173052\n",
      "epoch: 157 loss: 1.512494747596356\n",
      "epoch: 158 loss: 1.4938375811113567\n",
      "epoch: 159 loss: 1.6360133943225992\n",
      "epoch: 160 loss: 1.6473227605041478\n",
      "epoch: 161 loss: 1.6245852902577471\n",
      "epoch: 162 loss: 1.5845284974765477\n",
      "epoch: 163 loss: 1.469635790342969\n",
      "epoch: 164 loss: 1.5087189395724176\n",
      "epoch: 165 loss: 1.7289993813979285\n",
      "epoch: 166 loss: 1.6882896754112284\n",
      "epoch: 167 loss: 1.5044024913262246\n",
      "epoch: 168 loss: 1.5352155780515373\n",
      "epoch: 169 loss: 1.582764250448634\n",
      "epoch: 170 loss: 1.5303079348446276\n",
      "epoch: 171 loss: 1.646089639424799\n",
      "epoch: 172 loss: 1.6955334806117293\n",
      "epoch: 173 loss: 1.580226125918622\n",
      "epoch: 174 loss: 1.547609824290042\n",
      "epoch: 175 loss: 1.6487862169254055\n",
      "epoch: 176 loss: 1.6257182136469193\n",
      "epoch: 177 loss: 1.5008681462024567\n",
      "epoch: 178 loss: 1.6587562666604114\n",
      "epoch: 179 loss: 1.6471896988273433\n",
      "epoch: 180 loss: 1.4859164380990582\n",
      "epoch: 181 loss: 1.6220358155796109\n",
      "epoch: 182 loss: 1.5816959973846196\n",
      "epoch: 183 loss: 1.4933262705720343\n",
      "epoch: 184 loss: 1.6350499322431946\n",
      "epoch: 185 loss: 1.7132453596190051\n",
      "epoch: 186 loss: 1.6290123082718861\n",
      "epoch: 187 loss: 1.561390012578358\n",
      "epoch: 188 loss: 1.619106323342724\n",
      "epoch: 189 loss: 1.5590709464025554\n",
      "epoch: 190 loss: 1.590284140524913\n",
      "epoch: 191 loss: 1.6608467416311772\n",
      "epoch: 192 loss: 1.538694581326753\n",
      "epoch: 193 loss: 1.5496983630574803\n",
      "epoch: 194 loss: 1.6661260742794093\n",
      "epoch: 195 loss: 1.5921610834287478\n",
      "epoch: 196 loss: 1.4893712189915647\n",
      "epoch: 197 loss: 1.580972188765608\n",
      "epoch: 198 loss: 1.6838659526448607\n",
      "epoch: 199 loss: 1.6462392530208223\n",
      "epoch: 200 loss: 1.6060946547598267\n"
     ]
    }
   ],
   "source": [
    "# Training the SAE\n",
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_students):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_courses/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            \n",
    "            train_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.4992164448274343\n"
     ]
    }
   ],
   "source": [
    "# Testing the SAE\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_students):\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "    #target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "for id_user in range(test_set.shape[0]):\n",
    "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "\n",
    "\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_courses/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id = 1\n",
    "# movie_title = movies.iloc[:nb_courses, 1:2]\n",
    "# print(movie_title)\n",
    "# user_rating = training_set.data.numpy()[user_id, :].reshape(-1,1)\n",
    "# user_target = test_set.data.numpy()[user_id, :].reshape(-1,1)\n",
    " \n",
    "# user_input = Variable(training_set[user_id]).unsqueeze(0)\n",
    "# predicted = sae(user_input)\n",
    "# predicted = predicted.data.numpy().reshape(-1,1)\n",
    " \n",
    "# # Join all info in one dataset\n",
    "# result_array = np.hstack([movie_title, user_target, predicted])\n",
    "# result_array = result_array[result_array[:, 1] > 0]\n",
    "# result_df = pd.DataFrame(data=result_array, columns=['Movie', 'Target Rating', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  5.,  7.,  6.,  5.,  7.,  9.,  8.],\n",
       "        [ 0.,  4.,  0.,  7.,  6.,  0., 10.,  9.,  8.],\n",
       "        [ 8.,  8.,  7.,  9.,  7.,  7., 10., 10., 10.],\n",
       "        [ 0.,  0.,  7.,  0.,  7.,  0., 10.,  7., 10.],\n",
       "        [ 6.,  9.,  8.,  7.,  7.,  0., 10., 10.,  8.],\n",
       "        [10., 10.,  6.,  8.,  9.,  8., 10.,  9., 10.],\n",
       "        [ 7.,  7.,  5.,  7.,  7.,  5., 10.,  9., 10.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  9.,  8.,  7.],\n",
       "        [ 7.,  7.,  6.,  7.,  8.,  7., 10., 10., 10.],\n",
       "        [ 6.,  7.,  8.,  6.,  7.,  6., 10., 10., 10.],\n",
       "        [10.,  7.,  0.,  6.,  7.,  6., 10., 10., 10.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MA101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PH100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BE10105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>BE110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BE103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>EC100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PH110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>EC110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CS110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0     MA101\n",
       "1     PH100\n",
       "2   BE10105\n",
       "3     BE110\n",
       "4     BE103\n",
       "5     EC100\n",
       "6     PH110\n",
       "7     EC110\n",
       "8     CS110"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=data.columns\n",
    "c=columns.tolist()\n",
    "d=pd.DataFrame(c)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 1)\n"
     ]
    }
   ],
   "source": [
    "student_id = 4\n",
    "print(movie_title.shape)\n",
    "student_grade = training_set.data.numpy()[student_id, :].reshape(-1,1)\n",
    "user_target = test_set.data.numpy()[student_id, :].reshape(-1,1)\n",
    " \n",
    "user_input = Variable(training_set[student_id]).unsqueeze(0)\n",
    "predicted = sae(user_input)\n",
    "predicted = predicted.data.numpy().reshape(-1,1)\n",
    " \n",
    "# Join all info in one dataset\n",
    "result_array = np.hstack([d, user_target, predicted])\n",
    "result_array = result_array[result_array[:, 1] > 0]\n",
    "result_df = pd.DataFrame(data=result_array, columns=['courses', 'Target Rating', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courses</th>\n",
       "      <th>Target Rating</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MA101</td>\n",
       "      <td>6</td>\n",
       "      <td>6.30541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PH100</td>\n",
       "      <td>9</td>\n",
       "      <td>6.65035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BE10105</td>\n",
       "      <td>8</td>\n",
       "      <td>6.50106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>BE110</td>\n",
       "      <td>7</td>\n",
       "      <td>7.73212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BE103</td>\n",
       "      <td>7</td>\n",
       "      <td>7.14605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>PH110</td>\n",
       "      <td>10</td>\n",
       "      <td>8.15488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>EC110</td>\n",
       "      <td>10</td>\n",
       "      <td>10.1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>CS110</td>\n",
       "      <td>8</td>\n",
       "      <td>10.5107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    courses Target Rating Predicted\n",
       "0     MA101             6   6.30541\n",
       "1     PH100             9   6.65035\n",
       "2   BE10105             8   6.50106\n",
       "3     BE110             7   7.73212\n",
       "4     BE103             7   7.14605\n",
       "5     PH110            10   8.15488\n",
       "6     EC110            10   10.1389\n",
       "7     CS110             8   10.5107"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.],\n",
       "       [ 6.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 0.],\n",
       "       [10.],\n",
       "       [ 8.],\n",
       "       [10.]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  5.,  6.,  6.,  0., 10.,  8., 10.],\n",
       "        [ 5.,  6.,  5.,  6.,  7.,  0., 10.,  9.,  9.],\n",
       "        [ 0.,  0.,  0.,  0.,  7.,  0.,  9.,  7.,  8.],\n",
       "        [10.,  8.,  0., 10.,  8.,  7., 10., 10.,  9.],\n",
       "        [ 0.,  0.,  9.,  6.,  6.,  0., 10.,  8.,  9.],\n",
       "        [ 7.,  7.,  8.,  8.,  6.,  0., 10., 10., 10.],\n",
       "        [ 6.,  6.,  5.,  0.,  6.,  5., 10., 10., 10.],\n",
       "        [ 7.,  9.,  8., 10.,  8.,  6., 10., 10., 10.],\n",
       "        [ 5.,  5.,  6.,  7.,  7.,  6.,  9., 10.,  9.],\n",
       "        [ 7.,  6.,  5.,  9.,  7.,  6., 10.,  9.,  9.],\n",
       "        [ 5.,  6.,  5.,  7.,  6.,  0., 10., 10.,  8.],\n",
       "        [10.,  8.,  7.,  9.,  6.,  7.,  9.,  8., 10.],\n",
       "        [ 5.,  6.,  0.,  7.,  6.,  5., 10., 10.,  9.],\n",
       "        [ 8.,  7.,  6.,  7.,  7.,  7., 10., 10., 10.],\n",
       "        [ 7.,  7.,  6., 10.,  7.,  7.,  9.,  8., 10.],\n",
       "        [ 9.,  9.,  8.,  8.,  8.,  9., 10., 10., 10.],\n",
       "        [ 9.,  7.,  0.,  8.,  7.,  9., 10., 10.,  9.],\n",
       "        [ 7.,  6.,  9., 10.,  8.,  6.,  9., 10., 10.],\n",
       "        [ 6.,  5.,  5.,  7.,  6.,  6., 10., 10., 10.],\n",
       "        [ 0.,  6.,  0.,  6.,  7.,  5.,  9.,  7.,  9.],\n",
       "        [ 6.,  4.,  0.,  0.,  5.,  0.,  9.,  7.,  8.],\n",
       "        [ 0.,  4.,  0.,  7.,  7.,  0.,  8.,  8., 10.],\n",
       "        [10., 10.,  9., 10.,  8.,  8., 10.,  9., 10.],\n",
       "        [ 8.,  6.,  0.,  0.,  9.,  5.,  9.,  9., 10.],\n",
       "        [ 0.,  6.,  0.,  0.,  6.,  0., 10.,  9., 10.],\n",
       "        [ 5.,  6.,  0.,  7.,  7.,  0.,  9.,  9., 10.],\n",
       "        [ 8.,  9.,  5.,  9.,  7.,  8., 10., 10., 10.],\n",
       "        [ 6.,  7.,  7.,  7.,  7.,  0., 10.,  9., 10.],\n",
       "        [ 9.,  7.,  8., 10.,  7.,  0., 10.,  8., 10.],\n",
       "        [ 0.,  0.,  0.,  0.,  7.,  0.,  9.,  8., 10.],\n",
       "        [ 0.,  5.,  0.,  6.,  8.,  0.,  9., 10.,  7.],\n",
       "        [ 5.,  6.,  0.,  0.,  7.,  0., 10.,  9., 10.],\n",
       "        [ 6.,  7.,  6.,  8.,  7.,  5., 10.,  9., 10.],\n",
       "        [ 7.,  9.,  8.,  7.,  7.,  7., 10.,  9.,  9.],\n",
       "        [ 8.,  9.,  7.,  9.,  8.,  9., 10., 10., 10.],\n",
       "        [ 7.,  8.,  9., 10.,  8.,  7., 10., 10., 10.],\n",
       "        [ 9., 10.,  6.,  8.,  9.,  7., 10., 10., 10.],\n",
       "        [ 6.,  7.,  8.,  0.,  6.,  6., 10.,  9.,  8.],\n",
       "        [ 0.,  5.,  5.,  6.,  7.,  0., 10.,  9.,  9.],\n",
       "        [ 6.,  9.,  5.,  7.,  9.,  7., 10., 10.,  9.],\n",
       "        [ 0.,  0.,  0.,  8.,  5.,  0.,  9.,  9.,  7.],\n",
       "        [10., 10.,  7.,  9.,  6.,  6., 10., 10., 10.],\n",
       "        [ 7.,  8.,  9.,  7.,  8.,  6., 10., 10., 10.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [9.],\n",
       "       [8.]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  5.,  6.,  6.,  0., 10.,  8., 10.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.13807  ],\n",
       "       [ 5.618593 ],\n",
       "       [ 7.492981 ],\n",
       "       [ 7.364008 ],\n",
       "       [ 6.6475687],\n",
       "       [ 7.511931 ],\n",
       "       [ 9.864161 ],\n",
       "       [ 7.822873 ],\n",
       "       [10.628405 ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "m=movies.iloc[0,:]\n",
    "print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title[:nb_courses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index= movies.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=data.columns\n",
    "c=columns.tolist()\n",
    "d=pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MA101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PH100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BE10105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>BE110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BE103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>EC100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PH110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>EC110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CS110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0     MA101\n",
       "1     PH100\n",
       "2   BE10105\n",
       "3     BE110\n",
       "4     BE103\n",
       "5     EC100\n",
       "6     PH110\n",
       "7     EC110\n",
       "8     CS110"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
